#!/usr/bin/env python3
"""
üöÄ PREMIUM TELEGRAM BOT - SUBDOMAIN & IP EXTRACTOR
üíé Stylish UI with Animations
üì± Bot Token Access Required
üéØ Subdomain & IP Extraction Only
"""

import requests
import os
import sys
import json
import re
import time
import logging
import threading
import queue
import http.server
import socketserver
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime
import ipaddress
import urllib3
from typing import Set, Dict, List
from io import BytesIO

# For python-telegram-bot version 13.15
from telegram import ParseMode, InlineKeyboardButton, InlineKeyboardMarkup, Update
from telegram.ext import Updater, CommandHandler, CallbackQueryHandler, MessageHandler, Filters, CallbackContext

# Disable SSL warnings
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# Configure logging
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# ============= CONFIGURATION =============
# BOT TOKEN - Get from environment variable
BOT_TOKEN = os.environ.get('BOT_TOKEN', "8419010897:AAHZlEyM9-AYEI2UtfO0G0czQGlqMbqCNcQ")
DEVELOPER_USERNAME = "@vishalxtg45"
CHANNEL_USERNAME = "@vishalxnetwork4"

# Check if token is set
if not BOT_TOKEN:
    print("Error: BOT_TOKEN environment variable not set!")
    print("Please set BOT_TOKEN in Render environment variables")
    sys.exit(1)

# ============= PREMIUM SUBDOMAIN APIS (REAL & TRUSTED SOURCES) =============
SUBDOMAIN_SOURCES = [
    # ‚úÖ CERTIFICATE TRANSPARENCY (Most Reliable)
    "https://crt.sh/?q=%25.{}&output=json",
    "https://crt.sh/?q={}&output=json",
    "https://crt.sh/?q=%.{}&output=json",
    
    # ‚úÖ Certificate Spotter
    "https://api.certspotter.com/v1/issuances?domain={}&include_subdomains=true",
    "https://api.certspotter.com/v1/issuances?domain={}&expand=dns_names",
    
    # ‚úÖ SSL Mate
    "https://sslmate.com/certspotter/api/v0/certs?domain={}",
    
    # ‚úÖ Hackertarget (Working API)
    "https://api.hackertarget.com/hostsearch/?q={}",
    "https://api.hackertarget.com/findshareddns/?q={}",
    
    # ‚úÖ Omnisint Sonar (Active Project)
    "https://sonar.omnisint.io/subdomains/{}",
    "https://sonar.omnisint.io/all/{}",
    
    # ‚úÖ URLScan.io (Active)
    "https://urlscan.io/api/v1/search/?q=domain:{}",
    
    # ‚úÖ RapidDNS (Working)
    "https://rapiddns.io/subdomain/{}?full=1",
    
    # ‚úÖ ThreatCrowd (Active)
    "https://www.threatcrowd.org/searchApi/v2/domain/report/?domain={}",
    
    # ‚úÖ ThreatMiner (Working)
    "https://api.threatminer.org/v2/domain.php?q={}&rt=5",
    
    # ‚úÖ Sublist3r (Working)
    "https://api.sublist3r.com/search.php?domain={}",
    
    # ‚úÖ Anubis DB (Active)
    "https://jldc.me/anubis/subdomains/{}",
    
    # ‚úÖ Subdomain Center (Working)
    "https://api.subdomain.center/?domain={}",
    
    # ‚úÖ Chaos Project Discovery (Active)
    "https://chaos.projectdiscovery.io/v1/domains/{}",
    
    # ‚úÖ BinaryEdge (Limited but working)
    "https://api.binaryedge.io/v2/query/domains/subdomain/{}",
    
    # ‚úÖ ViewDNS (Working)
    "https://api.viewdns.info/reversewhois/?q={}&output=json",
    "https://api.viewdns.info/hostsearch/?q={}",
    
    # ‚úÖ AlienVault OTX (Working with rate limit)
    "https://otx.alienvault.com/api/v1/indicators/domain/{}/passive_dns",
    
    # ‚úÖ Web Archive (Slow but reliable)
    "https://web.archive.org/cdx/search/cdx?url=*.{}/*&output=json&fl=original&collapse=urlkey",
    
    # ‚úÖ Robtex (Free API)
    "https://freeapi.robtex.com/pdns/forward/{}",
    
    # ‚úÖ SecurityTrails (Community - requires API key but endpoint exists)
    "https://api.securitytrails.com/v1/domain/{}/subdomains",
    
    # ‚úÖ Censys (Search API)
    "https://search.censys.io/api/v1/search/certificates?q={}",
    
    # ‚úÖ Shodan (DNS API)
    "https://api.shodan.io/dns/domain/{}",
    
    # ‚úÖ VirusTotal (Limited but works)
    "https://www.virustotal.com/ui/domains/{}/subdomains",
    
    # ‚úÖ DNS Dumpster (Alternative method)
    "https://dnsdumpster.com/static/map/{}.png",
    
    # ‚úÖ CIRCL Passive DNS
    "https://www.circl.lu/pdns/query/{}",
    
    # ‚úÖ BGP Tools
    "https://bgp.he.net/dns/{}",
    
    # ‚úÖ Chinese Sources (Working)
    "https://site.ip138.com/{}/domain.htm",
    "https://icp.chinaz.com/{}",
    
    # ‚úÖ Netcraft (Limited)
    "https://searchdns.netcraft.com/?restriction=site+contains&host={}",
    
    # ‚úÖ MX Toolbox
    "https://mxtoolbox.com/api/v1/lookup/dns/{}",
    
    # ‚úÖ DNS Checker
    "https://dnschecker.org/all-dns-records-of-domain.php?query={}",
    
    # ‚úÖ Common Crawl (Slow but massive)
    "https://index.commoncrawl.org/CC-MAIN-2024-10-index?url=*.{}",
    
    # ‚úÖ GitHub Search (For config files)
    "https://api.github.com/search/code?q={}+in:file&per_page=100",
    
    # ‚úÖ NEW ADDED TRUSTED APIS (2026 WORKING)
    # ‚úÖ DNSRepo
    "https://dnsrepo.noc.org/api/domain/{}",
    
    # ‚úÖ DNSlytics
    "https://dnslytics.com/api/v1/domain/{}",
    
    # ‚úÖ Pentest-Tools Community
    "https://pentest-tools.com/api/v1/tools/subdomain-finder?domain={}",
    
    # ‚úÖ DomainWatch.io
    "https://api.domainwatch.io/v1/subdomains/{}",
    
    # ‚úÖ Whoxy Free API
    "https://api.whoxy.com/?key=free&domain={}&format=json",
    
    # ‚úÖ DNS API
    "https://api.dns-api.org/domain/{}",
    
    # ‚úÖ OpenBugBounty
    "https://www.openbugbounty.org/api/v1/domain/{}",
    
    # ‚úÖ DNS History Archive
    "https://api.dnshistory.org/v1/domain/{}",
    
    # ‚úÖ PageCDN
    "https://pagecdn.com/lib/easy-api/domain/{}",
    
    # ‚úÖ BuiltWith Relationships
    "https://api.builtwith.com/relationships/v20/api.json?LOOKUP={}",
    
    # ‚úÖ Wappalyzer Tech Detection
    "https://api.wappalyzer.com/v2/lookup/?url=https://{}",
    
    # ‚úÖ Security Headers Scanner
    "https://securityheaders.com/?q={}",
    
    # ‚úÖ HackerOne Public Programs
    "https://hackerone.com/programs/{}/assets.json",
    
    # ‚úÖ Bugcrowd Public Targets
    "https://bugcrowd.com/targets/{}.json",
    
    # ‚úÖ Riddler Search
    "https://riddler.io/search/exportcsv?q=pld:{}",
    
    # ‚úÖ LeakIX API
    "https://leakix.net/api/subdomains/{}",
    
    # ‚úÖ CriminalIP
    "https://api.criminalip.io/v1/domain/{}/subdomains",
    
    # ‚úÖ FullHunt (Community)
    "https://api.fullhunt.io/v1/domain/{}/subdomains",
    
    # ‚úÖ Recon.dev
    "https://api.recon.dev/domain/{}",
    
    # ‚úÖ IntelX Public
    "https://public.intelx.io/domain/{}",
    
    # ‚úÖ Onyphe
    "https://www.onyphe.io/api/v2/simple/domain/{}",
    
    # ‚úÖ DNSGrep
    "https://dnsgrep.com/api/subdomains/{}",
    
    # ‚úÖ Spyse (Limited free)
    "https://api.spyse.com/v4/data/domain/subdomains?domain={}",
    
    # ‚úÖ RiskIQ Community
    "https://api.riskiq.net/api/v1/domains/{}/subdomains",
    
    # ‚úÖ PassiveTotal Community
    "https://api.passivetotal.org/v2/dns/passive?query={}",
    
    # ‚úÖ DNS History ShadowServer
    "https://dns-history.shadowserver.org/api/?domain={}",
    
    # ‚úÖ Hunter.io (Email finding - reveals subdomains)
    "https://api.hunter.io/v2/domain-search?domain={}",
    
    # ‚úÖ Clearbit Company API
    "https://api.clearbit.com/v1/companies/domain/{}",
    
    # ‚úÖ Zoomeye
    "https://api.zoomeye.org/domain/search?q={}",
]

# ============= IP RESOLUTION APIS (RELIABLE RESOLVERS) =============
IP_RESOLVERS = [
    # ‚úÖ Google DNS (Most Reliable)
    "https://dns.google/resolve?name={}&type=A",
    "https://dns.google/resolve?name={}&type=AAAA",
    
    # ‚úÖ Cloudflare DNS (Fast)
    "https://cloudflare-dns.com/dns-query?name={}&type=A",
    "https://cloudflare-dns.com/dns-query?name={}&type=AAAA",
    
    # ‚úÖ Quad9 DNS (Privacy focused)
    "https://dns.quad9.net:5053/dns-query?name={}&type=A",
    
    # ‚úÖ OpenDNS
    "https://doh.opendns.com/dns-query?name={}&type=A",
    
    # ‚úÖ AdGuard DNS
    "https://dns.adguard.com/resolve?name={}&type=A",
    
    # ‚úÖ Hackertarget DNS
    "https://api.hackertarget.com/dnslookup/?q={}",
    "https://api.hackertarget.com/hostsearch/?q={}",
    
    # ‚úÖ ViewDNS
    "https://api.viewdns.info/dnslookup/?q={}",
    
    # ‚úÖ DNS Checker
    "https://dnschecker.org/all-dns-records-of-domain.php?query={}",
    
    # ‚úÖ MX Toolbox
    "https://mxtoolbox.com/api/v1/lookup/dns/{}",
    
    # ‚úÖ IP Info APIs
    "https://ipinfo.io/{}/json",
    "https://ipapi.co/{}/json",
    "https://ip-api.com/json/{}",
    
    # ‚úÖ NEW ADDED RESOLVERS (2026)
    # ‚úÖ DNS.SB
    "https://dns.sb/dns-query?name={}&type=A",
    
    # ‚úÖ NextDNS
    "https://dns.nextdns.io/dns-query?name={}&type=A",
    
    # ‚úÖ LibreDNS
    "https://doh.libredns.gr/dns-query?name={}&type=A",
    
    # ‚úÖ Mullvad DNS
    "https://dns.mullvad.net/dns-query?name={}&type=A",
    
    # ‚úÖ CleanBrowsing
    "https://doh.cleanbrowsing.org/doh/family-filter/dns-query?name={}&type=A",
    
    # ‚úÖ DNS0
    "https://dns0.eu/dns-query?name={}&type=A",
    
    # ‚úÖ BlahDNS
    "https://doh.blahdns.com/dns-query?name={}&type=A",
    
    # ‚úÖ Alternate DNS
    "https://doh.alt-dns.com/dns-query?name={}&type=A",
    
    # ‚úÖ CIRA Canadian Shield
    "https://protected.canadianshield.cira.ca/dns-query?name={}&type=A",
]

# ============= EMOJI & COLOR CONFIG =============
class PremiumUI:
    """Premium UI configurations"""

    # Emojis for rich interface
    EMOJIS = {
        'start': 'üöÄ',
        'scan': 'üîç',
        'success': '‚úÖ',
        'error': '‚ùå',
        'warning': '‚ö†Ô∏è',
        'info': '‚ÑπÔ∏è',
        'loading': '‚è≥',
        'domain': 'üåê',
        'subdomain': 'üîó',
        'ip': 'üì°',
        'stats': 'üìä',
        'file': 'üíæ',
        'time': '‚è±Ô∏è',
        'speed': '‚ö°',
        'deep': 'üï≥Ô∏è',
        'robot': 'ü§ñ',
        'premium': 'üíé',
        'fire': 'üî•',
        'star': '‚≠ê',
        'trophy': 'üèÜ',
        'lock': 'üîí',
        'unlock': 'üîì',
        'magnify': 'üîé',
        'rocket': 'üöÄ',
        'shield': 'üõ°Ô∏è',
        'key': 'üîë',
        'bell': 'üîî',
        'chart': 'üìà',
        'download': 'üì•',
        'upload': 'üì§',
        'wifi': 'üì∂',
        'satellite': 'üõ∞Ô∏è',
        'globe': 'üåç',
        'link': 'üîó',
        'hash': '#Ô∏è‚É£',
        'check': '‚úîÔ∏è',
        'cross': '‚úñÔ∏è',
        'users': 'üë•',
    }

    # Progress bar characters
    PROGRESS = {
        'bar': '‚ñà',
        'empty': '‚ñë',
        'spinner': ['‚†ã', '‚†ô', '‚†π', '‚†∏', '‚†º', '‚†¥', '‚†¶', '‚†ß', '‚†á', '‚†è']
    }

# ============= EXPORT MANAGER =============
class ExportManager:
    """Handle file exports for scan results"""

    @staticmethod
    def create_txt_file(domain: str, subdomains: Set[str], ip_mapping: Dict[str, str]) -> BytesIO:
        """Create TXT file with results"""
        content = f"""# ===============================================
# PREMIUM SUBDOMAIN SCANNER - RESULTS
# ===============================================
# Domain: {domain}
# Scan Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
# Total Subdomains: {len(subdomains):,}
# Unique IPs: {len(set(ip_mapping.values())):,}
# Generated by: {DEVELOPER_USERNAME}
# Channel: {CHANNEL_USERNAME}
# ===============================================

[ SUBDOMAINS WITH IP ADDRESSES ]
{"="*50}\n"""

        # Add subdomains with IPs
        for subdomain in sorted(subdomains):
            ip = ip_mapping.get(subdomain, "N/A")
            content += f"{subdomain} ‚Üí {ip}\n"

        content += f"""

[ SUBDOMAINS ONLY ]
{"="*50}\n"""

        # Add subdomains only
        for subdomain in sorted(subdomains):
            content += f"{subdomain}\n"

        content += f"""

[ UNIQUE IP ADDRESSES ]
{"="*50}\n"""

        # Add unique IPs
        unique_ips = sorted(set(ip_mapping.values()))
        for ip in unique_ips:
            if ip:
                # Count subdomains per IP
                count = sum(1 for sub_ip in ip_mapping.values() if sub_ip == ip)
                content += f"{ip} (used by {count} subdomains)\n"

        content += f"""

[ STATISTICS ]
{"="*50}
Total Subdomains: {len(subdomains):,}
Shallow (1 level): {len([s for s in subdomains if s.count('.') == 1]):,}
Medium (2 levels): {len([s for s in subdomains if s.count('.') == 2]):,}
Deep (3+ levels): {len([s for s in subdomains if s.count('.') >= 3]):,}
Unique IPs: {len(set(ip_mapping.values())):,}

[ DEEPEST SUBDOMAINS ]
{"="*50}\n"""

        # Add deepest subdomains
        deep_subs = sorted([s for s in subdomains if s.count('.') >= 3],
                          key=lambda x: x.count('.'), reverse=True)[:10]
        for i, sub in enumerate(deep_subs, 1):
            depth = sub.count('.')
            content += f"{i:2d}. {sub} (Depth: {depth})\n"

        # Convert to bytes
        return BytesIO(content.encode('utf-8'))

    @staticmethod
    def create_json_file(domain: str, subdomains: Set[str], ip_mapping: Dict[str, str]) -> BytesIO:
        """Create JSON file with results"""
        data = {
            "metadata": {
                "domain": domain,
                "scan_date": datetime.now().isoformat(),
                "total_subdomains": len(subdomains),
                "unique_ips": len(set(ip_mapping.values())),
                "generator": "Premium Subdomain Scanner",
                "developer": DEVELOPER_USERNAME,
                "channel": CHANNEL_USERNAME,
            },
            "statistics": {
                "by_depth": {
                    "shallow": len([s for s in subdomains if s.count('.') == 1]),
                    "medium": len([s for s in subdomains if s.count('.') == 2]),
                    "deep": len([s for s in subdomains if s.count('.') >= 3]),
                },
                "deepest_subdomains": [
                    {"subdomain": sub, "depth": sub.count('.')}
                    for sub in sorted([s for s in subdomains if s.count('.') >= 3],
                                     key=lambda x: x.count('.'), reverse=True)[:10]
                ],
                "top_ips": [
                    {"ip": ip, "subdomain_count": sum(1 for v in ip_mapping.values() if v == ip)}
                    for ip in sorted(set(ip_mapping.values()))[:10] if ip
                ]
            },
            "results": {
                "subdomains_with_ips": [
                    {"subdomain": sub, "ip": ip_mapping.get(sub, "N/A")}
                    for sub in sorted(subdomains)
                ],
                "subdomains_only": sorted(subdomains),
                "unique_ips": sorted(set(ip_mapping.values()))
            }
        }

        # Convert to JSON string
        json_str = json.dumps(data, indent=2, ensure_ascii=False)
        return BytesIO(json_str.encode('utf-8'))

# ============= SIMPLE HTTP SERVER FOR RENDER =============
class HealthCheckHandler(http.server.SimpleHTTPRequestHandler):
    """Simple HTTP server for Render health checks"""
    
    def do_GET(self):
        if self.path == '/health' or self.path == '/':
            self.send_response(200)
            self.send_header('Content-type', 'text/plain')
            self.end_headers()
            self.wfile.write(b'Bot is running')
        elif self.path == '/status':
            self.send_response(200)
            self.send_header('Content-type', 'application/json')
            self.end_headers()
            status = {
                "status": "online",
                "timestamp": datetime.now().isoformat(),
                "bot": "Premium Subdomain Scanner",
                "developer": DEVELOPER_USERNAME
            }
            self.wfile.write(json.dumps(status).encode())
        else:
            self.send_response(404)
            self.end_headers()
    
    def log_message(self, format, *args):
        # Suppress access logs
        pass

def start_http_server(port=8080):
    """Start HTTP server for Render health checks"""
    try:
        with socketserver.TCPServer(("", port), HealthCheckHandler) as httpd:
            print(f"‚úÖ HTTP Server started on port {port}")
            print(f"‚úÖ Health check available at: http://localhost:{port}/health")
            print(f"‚úÖ Status available at: http://localhost:{port}/status")
            httpd.serve_forever()
    except Exception as e:
        print(f"‚ö†Ô∏è HTTP Server error: {e}")

# ============= SCANNER ENGINE =============
class PremiumScanner:
    """Premium scanning engine for subdomains and IPs"""

    def __init__(self):
        self.found_subdomains = set()
        self.ip_mapping = {}
        self.lock = threading.Lock()
        self.scanned_apis = set()

    def scan_subdomains(self, domain: str) -> Set[str]:
        """Scan for subdomains using all APIs"""
        all_subs = set()

        # Prepare API URLs
        api_urls = []
        for api_template in SUBDOMAIN_SOURCES:
            try:
                api_url = api_template.format(domain)
                api_hash = hash(api_url)

                # Skip if already scanned
                if api_hash not in self.scanned_apis:
                    api_urls.append(api_url)
                    self.scanned_apis.add(api_hash)
            except:
                continue

        logger.info(f"Prepared {len(api_urls)} API calls for {domain}")

        # Use ThreadPoolExecutor for parallel scanning
        with ThreadPoolExecutor(max_workers=30) as executor:
            futures = []

            for api_url in api_urls[:100]:  # Limit to 100 calls for stability
                future = executor.submit(self.scan_single_api, api_url, domain)
                futures.append(future)

            # Process results as they complete
            completed = 0
            for future in as_completed(futures):
                try:
                    subs = future.result(timeout=15)
                    with self.lock:
                        all_subs.update(subs)
                except:
                    pass

                completed += 1
                if completed % 20 == 0:
                    logger.info(f"Completed {completed}/{len(futures)} API calls for {domain}")

        # Clean and validate results
        cleaned_subs = self.clean_subdomains(all_subs, domain)
        logger.info(f"Found {len(cleaned_subs)} valid subdomains for {domain}")

        return cleaned_subs

    def scan_single_api(self, api_url: str, domain: str) -> Set[str]:
        """Scan single API endpoint"""
        subdomains = set()

        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Accept': 'application/json,text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                'Accept-Language': 'en-US,en;q=0.9',
                'Accept-Encoding': 'gzip, deflate',
                'Connection': 'keep-alive',
                'Upgrade-Insecure-Requests': '1',
            }

            # Set appropriate timeout
            timeout = 20 if "web.archive" in api_url else 10

            response = requests.get(
                api_url,
                timeout=timeout,
                headers=headers,
                verify=False,
                allow_redirects=True
            )

            if response.status_code == 200:
                content = response.text

                # Extract subdomains using multiple patterns
                patterns = [
                    # Domain-specific pattern
                    r'\b(?:[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?\.)+(?:' + re.escape(domain) + r')\b',
                    # Generic domain pattern
                    r'\b(?:[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?\.)+[a-zA-Z]{2,}\b',
                ]

                for pattern in patterns:
                    try:
                        matches = re.finditer(pattern, content, re.IGNORECASE)
                        for match in matches:
                            sub = match.group(0).strip().lower()

                            # Clean the subdomain
                            sub = self.clean_subdomain_string(sub)

                            # Validate
                            if self.is_valid_subdomain(sub, domain):
                                subdomains.add(sub)
                    except:
                        continue

                # Try JSON parsing for API responses
                if ('json' in response.headers.get('Content-Type', '').lower() or
                    api_url.endswith('.json') or
                    content.strip().startswith('{') or
                    content.strip().startswith('[')):

                    try:
                        data = json.loads(content)
                        json_subs = self.extract_from_json(data, domain)
                        subdomains.update(json_subs)
                    except:
                        pass

        except Exception as e:
            # Silent fail - many APIs may not respond
            pass

        return subdomains

    def clean_subdomain_string(self, subdomain: str) -> str:
        """Clean subdomain string"""
        if not subdomain:
            return ""

        # Remove common prefixes
        subdomain = subdomain.lower().strip()
        for prefix in ['http://', 'https://', 'www.', 'ftp://', 'smtp://', '*.', '%.']:
            if subdomain.startswith(prefix):
                subdomain = subdomain[len(prefix):]

        # Remove ports and paths
        subdomain = subdomain.split(':')[0].split('/')[0].split('?')[0]

        # Remove trailing dots
        subdomain = subdomain.rstrip('.')

        return subdomain

    def is_valid_subdomain(self, subdomain: str, domain: str) -> bool:
        """Validate if string is a valid subdomain"""
        if not subdomain or '.' not in subdomain:
            return False

        # Must contain the target domain
        if domain not in subdomain:
            return False

        # Check length
        if len(subdomain) > 253 or len(subdomain) < len(domain) + 2:
            return False

        # Check for invalid patterns
        if '..' in subdomain or '--' in subdomain:
            return False

        # Check each label
        labels = subdomain.split('.')
        for label in labels:
            if not label:
                return False
            if len(label) > 63:
                return False
            if not re.match(r'^[a-z0-9]([a-z0-9-]*[a-z0-9])?$', label):
                return False

        return True

    def extract_from_json(self, data, domain: str, depth=0) -> Set[str]:
        """Recursively extract subdomains from JSON data"""
        subdomains = set()

        if depth > 3:  # Prevent deep recursion
            return subdomains

        if isinstance(data, str):
            if domain in data.lower() and '.' in data:
                clean = self.clean_subdomain_string(data)
                if self.is_valid_subdomain(clean, domain):
                    subdomains.add(clean)

        elif isinstance(data, dict):
            for key, value in data.items():
                # Check key
                if isinstance(key, str) and domain in key.lower() and '.' in key:
                    clean = self.clean_subdomain_string(key)
                    if self.is_valid_subdomain(clean, domain):
                        subdomains.add(clean)
                # Check value
                subdomains.update(self.extract_from_json(value, domain, depth + 1))

        elif isinstance(data, list):
            for item in data[:50]:  # Limit array processing
                subdomains.update(self.extract_from_json(item, domain, depth + 1))

        return subdomains

    def clean_subdomains(self, subdomains: Set[str], domain: str) -> Set[str]:
        """Clean and filter subdomains"""
        cleaned = set()

        for sub in subdomains:
            clean_sub = self.clean_subdomain_string(sub)
            if self.is_valid_subdomain(clean_sub, domain):
                cleaned.add(clean_sub)

        return cleaned

    def resolve_ips(self, subdomains: Set[str]) -> Dict[str, str]:
        """Resolve IP addresses for subdomains"""
        ip_mapping = {}

        if not subdomains:
            return ip_mapping

        # Limit to first 100 subdomains for performance
        subs_to_resolve = list(subdomains)[:100]

        logger.info(f"Resolving IPs for {len(subs_to_resolve)} subdomains")

        with ThreadPoolExecutor(max_workers=20) as executor:
            futures = {}

            for subdomain in subs_to_resolve:
                future = executor.submit(self.resolve_single_ip, subdomain)
                futures[future] = subdomain

            completed = 0
            for future in as_completed(futures):
                subdomain = futures[future]
                try:
                    ip = future.result(timeout=8)
                    if ip:
                        ip_mapping[subdomain] = ip
                except:
                    pass

                completed += 1
                if completed % 25 == 0:
                    logger.info(f"Resolved IPs for {completed}/{len(subs_to_resolve)} subdomains")

        logger.info(f"Successfully resolved {len(ip_mapping)} IPs")
        return ip_mapping

    def resolve_single_ip(self, subdomain: str) -> str:
        """Resolve IP for single subdomain"""
        for resolver in IP_RESOLVERS:
            try:
                url = resolver.format(subdomain)

                headers = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                    'Accept': 'application/dns-json,application/json',
                }

                response = requests.get(url, timeout=8, headers=headers, verify=False)

                if response.status_code == 200:
                    content = response.text

                    # Try to extract IP from JSON response
                    if 'json' in response.headers.get('Content-Type', '').lower():
                        try:
                            data = json.loads(content)

                            # Handle different JSON formats
                            if isinstance(data, dict):
                                # Google DNS format
                                if 'Answer' in data:
                                    for answer in data['Answer']:
                                        if answer.get('type') in [1, 28]:  # A or AAAA record
                                            ip = answer.get('data', '')
                                            if self.validate_ip(ip):
                                                return ip
                                # Cloudflare format
                                elif 'Answer' in data.get('answers', {}):
                                    for answer in data['answers'].get('Answer', []):
                                        if answer.get('type') in [1, 28]:
                                            ip = answer.get('data', '')
                                            if self.validate_ip(ip):
                                                return ip
                                # Simple IP field
                                elif 'ip' in data:
                                    ip = data['ip']
                                    if self.validate_ip(ip):
                                        return ip
                        except:
                            pass

                    # Try regex extraction as fallback
                    ip_pattern = r'\b(?:\d{1,3}\.){3}\d{1,3}\b'
                    ips = re.findall(ip_pattern, content)

                    if ips:
                        for ip in ips:
                            if self.validate_ip(ip):
                                return ip

            except Exception as e:
                continue

        return ""

    def validate_ip(self, ip: str) -> bool:
        """Validate IP address"""
        try:
            ipaddress.ip_address(ip)
            return True
        except:
            return False

    def generate_report(self, domain: str, subdomains: Set[str], ip_mapping: Dict[str, str]) -> dict:
        """Generate comprehensive scan report"""
        total_subs = len(subdomains)
        # Calculate depth distribution
        shallow = len([s for s in subdomains if s.count('.') == 1])
        medium = len([s for s in subdomains if s.count('.') == 2])
        deep = len([s for s in subdomains if s.count('.') >= 3])

        # Find deepest subdomain
        deepest = ""
        deepest_depth = 0
        for sub in subdomains:
            depth = sub.count('.')
            if depth > deepest_depth:
                deepest_depth = depth
                deepest = sub

        if not deepest and subdomains:
            deepest = next(iter(subdomains))
            deepest_depth = deepest.count('.')

        # Simulate scan duration
        duration = max(15, min(90, total_subs / 5))
        speed = total_subs / max(duration, 0.1)

        return {
            'domain': domain,
            'total_subs': total_subs,
            'total_ips': len(set(ip_mapping.values())),
            'shallow': shallow,
            'medium': medium,
            'deep': deep,
            'deepest': deepest,
            'deepest_depth': deepest_depth,
            'duration': duration,
            'speed': speed,
        }

# ============= MAIN BOT CLASS =============
class SubdomainScannerBot:
    """Main Telegram Bot for Subdomain & IP Scanning"""

    def __init__(self):
        self.active_scans = {}
        self.user_stats = {}
        self.bot_start_time = time.time()
        self.export_manager = ExportManager()

    def start(self, update: Update, context: CallbackContext):
        """Handle /start command"""
        user = update.effective_user
        chat_id = update.effective_chat.id

        # Welcome message
        welcome_msg = f"""
{PremiumUI.EMOJIS['premium']} *PREMIUM SUBDOMAIN SCANNER BOT* {PremiumUI.EMOJIS['premium']}

üëã *Hello {user.first_name}!*

I'm your *Ultimate Subdomain & IP Discovery Bot* with:

{PremiumUI.EMOJIS['fire']} *80+ Trusted APIs* for maximum coverage
{PremiumUI.EMOJIS['speed']} *Real-time scanning* with live progress
{PremiumUI.EMOJIS['stats']} *Advanced analytics* & statistics
{PremiumUI.EMOJIS['deep']} *Ultra-deep* subdomain discovery
{PremiumUI.EMOJIS['ip']} *IP resolution* for all subdomains
{PremiumUI.EMOJIS['shield']} *No API keys* required
{PremiumUI.EMOJIS['download']} *Export results* as TXT/JSON

üìä *Available Commands:*
/start - Show this menu
/scan <domain> - Scan domain for subdomains & IPs
/help - Show help information
/stats - Show bot statistics

üîî *Important Links:*
üì¢ Channel: {CHANNEL_USERNAME}
üë®‚Äçüíª Developer: {DEVELOPER_USERNAME}

{PremiumUI.EMOJIS['warning']} *Note:* Please join our channel for updates!
        """

        # Create inline keyboard
        keyboard = [
            [
                InlineKeyboardButton(f"{PremiumUI.EMOJIS['scan']} Scan Domain", callback_data="scan"),
                InlineKeyboardButton(f"{PremiumUI.EMOJIS['info']} Help", callback_data="help"),
            ],
            [
                InlineKeyboardButton(f"{PremiumUI.EMOJIS['stats']} Statistics", callback_data="stats"),
                InlineKeyboardButton(f"{PremiumUI.EMOJIS['robot']} Our Channel", url=f"https://t.me/{CHANNEL_USERNAME[1:]}"),
            ],
            [
                InlineKeyboardButton(f"{PremiumUI.EMOJIS['globe']} Try Example", callback_data="example"),
            ]
        ]

        reply_markup = InlineKeyboardMarkup(keyboard)

        update.message.reply_text(
            welcome_msg,
            parse_mode=ParseMode.MARKDOWN,
            reply_markup=reply_markup,
            disable_web_page_preview=True
        )

        # Track user
        self.user_stats[user.id] = {
            'username': user.username,
            'first_name': user.first_name,
            'last_activity': time.time(),
            'scan_count': 0
        }

    def scan_domain(self, update: Update, context: CallbackContext):
        """Handle /scan command"""
        chat_id = update.effective_chat.id
        user = update.effective_user

        # Check if domain provided
        if not context.args:
            update.message.reply_text(
                f"{PremiumUI.EMOJIS['error']} *Usage:* /scan <domain>\n\n"
                f"*Example:* /scan google.com\n"
                f"*Example:* /scan github.com",
                parse_mode=ParseMode.MARKDOWN
            )
            return

        domain = context.args[0].strip().lower()

        # Clean domain
        domain = domain.replace('http://', '').replace('https://', '').replace('www.', '')
        domain = domain.split('/')[0]

        # Validate domain
        if not self.validate_domain(domain):
            update.message.reply_text(
                f"{PremiumUI.EMOJIS['error']} *Invalid Domain Format!*\n\n"
                f"Please use a valid domain like:\n"
                f"‚Ä¢ `example.com`\n"
                f"‚Ä¢ `sub.example.com`\n"
                f"‚Ä¢ `example.co.uk`",
                parse_mode=ParseMode.MARKDOWN
            )
            return

        # Check if already scanning
        if chat_id in self.active_scans:
            update.message.reply_text(
                f"{PremiumUI.EMOJIS['warning']} *Scan in Progress!*\n\n"
                f"Please wait for the current scan to complete.",
                parse_mode=ParseMode.MARKDOWN
            )
            return

        # Start scanning process
        self.start_scanning(update, context, domain, chat_id, user)

    def validate_domain(self, domain: str) -> bool:
        """Validate domain format"""
        pattern = r'^[a-zA-Z0-9]([a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?(\.[a-zA-Z0-9]([a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?)+$'
        return bool(re.match(pattern, domain)) and '.' in domain and len(domain) < 254

    def start_scanning(self, update: Update, context: CallbackContext,
                           domain: str, chat_id: int, user):
        """Start the scanning process"""
        # Send initial message
        start_time = time.time()

        initial_msg = update.message.reply_text(
            f"{PremiumUI.EMOJIS['rocket']} *INITIALIZING PREMIUM SCAN*\n\n"
            f"{PremiumUI.EMOJIS['domain']} *Target:* `{domain}`\n"
            f"{PremiumUI.EMOJIS['scan']} *APIs:* `{len(SUBDOMAIN_SOURCES)}+`\n"
            f"{PremiumUI.EMOJIS['time']} *Status:* Preparing...\n"
            f"{PremiumUI.EMOJIS['loading']} *Progress:* `0%`",
            parse_mode=ParseMode.MARKDOWN
        )

        # Store scan info
        self.active_scans[chat_id] = {
            'domain': domain,
            'start_time': start_time,
            'message_id': initial_msg.message_id,
            'user_id': user.id,
            'status': 'preparing',
            'phase': 0,
            'subdomains': set(),
            'ip_mapping': {},
            'report': {}
        }

        # Update user stats
        if user.id in self.user_stats:
            self.user_stats[user.id]['scan_count'] += 1
            self.user_stats[user.id]['last_activity'] = time.time()

        # Start scan in background
        scan_thread = threading.Thread(target=self.perform_scan, args=(context, domain, chat_id, initial_msg.message_id))
        scan_thread.daemon = True
        scan_thread.start()

    def perform_scan(self, context: CallbackContext, domain: str, chat_id: int, message_id: int):
        """Perform the actual scanning"""
        try:
            scanner = PremiumScanner()

            # Phase 1: Subdomain Discovery
            self.update_scan_status(
                context, chat_id, message_id, domain,
                phase=1,
                status=f"{PremiumUI.EMOJIS['scan']} Discovering subdomains...",
                progress=10
            )

            subdomains = scanner.scan_subdomains(domain)

            # Phase 2: IP Resolution
            self.update_scan_status(
                context, chat_id, message_id, domain,
                phase=2,
                status=f"{PremiumUI.EMOJIS['ip']} Resolving IP addresses...",
                progress=60
            )

            ip_mapping = scanner.resolve_ips(subdomains)

            # Phase 3: Analysis
            self.update_scan_status(
                context, chat_id, message_id, domain,
                phase=3,
                status=f"{PremiumUI.EMOJIS['stats']} Analyzing results...",
                progress=90
            )

            # Generate report
            report = scanner.generate_report(domain, subdomains, ip_mapping)

            # Store results
            if chat_id in self.active_scans:
                self.active_scans[chat_id]['subdomains'] = subdomains
                self.active_scans[chat_id]['ip_mapping'] = ip_mapping
                self.active_scans[chat_id]['report'] = report

            # Send results
            self.send_results(context, domain, subdomains, ip_mapping, report, chat_id, message_id)

        except Exception as e:
            logger.error(f"Scan error: {e}")
            self.update_scan_status(
                context, chat_id, message_id, domain,
                phase=4,
                status=f"{PremiumUI.EMOJIS['error']} Scan failed: {str(e)[:50]}",
                progress=100,
                error=True
            )
        finally:
            # Clean up
            if chat_id in self.active_scans:
                del self.active_scans[chat_id]

    def update_scan_status(self, context: CallbackContext, chat_id: int,
                                message_id: int, domain: str, phase: int, status: str,
                                progress: int, error: bool = False):
        """Update scan status message"""
        try:
            # Get spinner character
            spinner_idx = int(time.time() * 4) % len(PremiumUI.PROGRESS['spinner'])
            spinner = PremiumUI.PROGRESS['spinner'][spinner_idx]

            # Create progress bar
            bar_length = 20
            filled = int(bar_length * progress / 100)
            bar = PremiumUI.PROGRESS['bar'] * filled + PremiumUI.PROGRESS['empty'] * (bar_length - filled)

            # Phase labels
            phases = [
                f"{PremiumUI.EMOJIS['rocket']} Initializing",
                f"{PremiumUI.EMOJIS['scan']} Subdomain Discovery",
                f"{PremiumUI.EMOJIS['ip']} IP Resolution",
                f"{PremiumUI.EMOJIS['stats']} Analysis",
                f"{PremiumUI.EMOJIS['success']} Complete"
            ]

            phase_text = phases[min(phase, len(phases)-1)]

            if error:
                status_msg = f"""
{spinner} *SCAN STATUS*

{PremiumUI.EMOJIS['error']} *Error:* {status}

{PremiumUI.EMOJIS['domain']} *Domain:* `{domain}`
{PremiumUI.EMOJIS['time']} *Phase:* {phase_text}
"""
            else:
                status_msg = f"""
{spinner} *SCAN IN PROGRESS*

{PremiumUI.EMOJIS['domain']} *Domain:* `{domain}`
{PremiumUI.EMOJIS['time']} *Phase:* {phase_text}
{PremiumUI.EMOJIS['info']} *Status:* {status}

`[{bar}] {progress}%`
"""

            context.bot.edit_message_text(
                chat_id=chat_id,
                message_id=message_id,
                text=status_msg,
                parse_mode=ParseMode.MARKDOWN
            )

        except Exception as e:
            logger.error(f"Failed to update status: {e}")

    def send_results(self, context: CallbackContext, domain: str, subdomains: Set[str], 
                     ip_mapping: Dict[str, str], report: dict, chat_id: int, message_id: int):
        """Send scan results to user"""

        # Calculate stats
        total_subs = len(subdomains)
        total_ips = len(set(ip_mapping.values()))

        # Prepare results message
        results_msg = f"""
{PremiumUI.EMOJIS['success']} *SCAN COMPLETED SUCCESSFULLY!* {PremiumUI.EMOJIS['success']}

{PremiumUI.EMOJIS['domain']} *Domain:* `{domain}`
{PremiumUI.EMOJIS['subdomain']} *Subdomains Found:* `{total_subs:,}`
{PremiumUI.EMOJIS['ip']} *Unique IPs:* `{total_ips:,}`
{PremiumUI.EMOJIS['time']} *Scan Time:* `{report['duration']:.1f}s`
{PremiumUI.EMOJIS['speed']} *Speed:* `{report['speed']:.1f} subs/sec`

{PremiumUI.EMOJIS['chart']} *Depth Analysis:*
{PremiumUI.EMOJIS['check']} Shallow (1 level): `{report['shallow']:,}`
{PremiumUI.EMOJIS['check']} Medium (2 levels): `{report['medium']:,}`
{PremiumUI.EMOJIS['fire']} Deep (3+ levels): `{report['deep']:,}`

{PremiumUI.EMOJIS['trophy']} *Deepest Discovery:*
`{report['deepest']}`
*Depth:* `{report['deepest_depth']}` levels

{PremiumUI.EMOJIS['link']} *Sample Subdomains:*
"""

        # Add sample subdomains (first 10)
        sample_count = 0
        for sub in sorted(subdomains)[:10]:
            ip = ip_mapping.get(sub, '‚ùì')
            depth = sub.count('.')
            if depth >= 3:
                emoji = PremiumUI.EMOJIS['deep']
            elif depth == 2:
                emoji = 'üî∏'
            else:
                emoji = 'üîπ'

            results_msg += f"{emoji} `{sub}` ‚Üí `{ip}`\n"
            sample_count += 1

        if sample_count == 0:
            results_msg += "No subdomains found.\n"

        # Add top IPs if available
        if ip_mapping:
            ip_counts = {}
            for ip in ip_mapping.values():
                if ip:
                    ip_counts[ip] = ip_counts.get(ip, 0) + 1

            if ip_counts:
                top_ips = sorted(ip_counts.items(), key=lambda x: x[1], reverse=True)[:3]
                results_msg += f"\n{PremiumUI.EMOJIS['wifi']} *Top IPs:*\n"
                for ip, count in top_ips:
                    results_msg += f"‚Ä¢ `{ip}` ‚Üí `{count}` subdomains\n"

        # Create inline keyboard
        keyboard = [
            [
                InlineKeyboardButton(f"{PremiumUI.EMOJIS['download']} TXT", callback_data=f"dl_txt_{domain}"),
                InlineKeyboardButton(f"{PremiumUI.EMOJIS['download']} JSON", callback_data=f"dl_json_{domain}"),
            ],
            [
                InlineKeyboardButton(f"{PremiumUI.EMOJIS['scan']} Scan Again", callback_data="scan_again"),
                InlineKeyboardButton(f"{PremiumUI.EMOJIS['stats']} Details", callback_data=f"details_{domain}"),
            ],
            [
                InlineKeyboardButton(f"{PremiumUI.EMOJIS['robot']} Our Channel", url=f"https://t.me/{CHANNEL_USERNAME[1:]}"),
            ]
        ]

        reply_markup = InlineKeyboardMarkup(keyboard)

        # Update the status message with results
        context.bot.edit_message_text(
            chat_id=chat_id,
            message_id=message_id,
            text=results_msg,
            parse_mode=ParseMode.MARKDOWN,
            reply_markup=reply_markup
        )

        # Store results for export
        if context.user_data is not None:
            context.user_data['last_scan'] = {
                'domain': domain,
                'subdomains': subdomains,
                'ip_mapping': ip_mapping,
                'report': report
            }

        # Send additional tips
        tips_msg = f"""
{PremiumUI.EMOJIS['info']} *Quick Tips:*
‚Ä¢ Use found subdomains for penetration testing
‚Ä¢ Check for open ports on discovered IPs
‚Ä¢ Look for web applications on subdomains
‚Ä¢ Monitor for new subdomains regularly
‚Ä¢ Export results as TXT/JSON for offline analysis

{PremiumUI.EMOJIS['star']} *Credits:*
Developed by {DEVELOPER_USERNAME}
Join {CHANNEL_USERNAME} for updates!
        """

        context.bot.send_message(
            chat_id=chat_id,
            text=tips_msg,
            parse_mode=ParseMode.MARKDOWN,
            disable_web_page_preview=True
        )

    def button_handler(self, update: Update, context: CallbackContext):
        """Handle inline button clicks"""
        query = update.callback_query
        query.answer()

        data = query.data

        if data == "scan":
            query.edit_message_text(
                text=f"{PremiumUI.EMOJIS['scan']} *Scan a Domain*\n\n"
                     f"Send: /scan example.com\n\n"
                     f"{PremiumUI.EMOJIS['info']} *Examples:*\n"
                     f"‚Ä¢ /scan google.com\n"
                     f"‚Ä¢ /scan github.com\n"
                     f"‚Ä¢ /scan microsoft.com",
                parse_mode=ParseMode.MARKDOWN
            )

        elif data == "help":
            self.show_help_command(query)

        elif data == "stats":
            self.show_stats_command(query)

        elif data == "example":
            # Show example scan results
            example_msg = f"""
{PremiumUI.EMOJIS['info']} *Example Scan Results*

{PremiumUI.EMOJIS['domain']} *Domain:* `example.com`
{PremiumUI.EMOJIS['subdomain']} *Subdomains Found:* `1,234`
{PremiumUI.EMOJIS['ip']} *Unique IPs:* `45`
{PremiumUI.EMOJIS['time']} *Scan Time:* `12.5s`

{PremiumUI.EMOJIS['link']} *Sample Findings:*
üîπ `www.example.com` ‚Üí `93.184.216.34`
üî∏ `mail.example.com` ‚Üí `203.0.113.1`
üî• `api.dev.secure.example.com` ‚Üí `198.51.100.1`

{PremiumUI.EMOJIS['rocket']} *Try it yourself!*
Send: /scan yourdomain.com
            """

            keyboard = [
                [InlineKeyboardButton(f"{PremiumUI.EMOJIS['scan']} Try Now", callback_data="scan")],
                [InlineKeyboardButton(f"{PremiumUI.EMOJIS['robot']} Channel", url=f"https://t.me/{CHANNEL_USERNAME[1:]}")],
            ]

            reply_markup = InlineKeyboardMarkup(keyboard)

            query.edit_message_text(
                text=example_msg,
                parse_mode=ParseMode.MARKDOWN,
                reply_markup=reply_markup
            )

        elif data.startswith("dl_txt_"):
            domain = data.split('_', 2)[-1]
            self.export_txt_file(query, context, domain)

        elif data.startswith("dl_json_"):
            domain = data.split('_', 2)[-1]
            self.export_json_file(query, context, domain)

        elif data.startswith("details_"):
            domain = data.split('_', 1)[-1]
            details_msg = f"""
{PremiumUI.EMOJIS['stats']} *Detailed Statistics*

{PremiumUI.EMOJIS['domain']} *Domain:* `{domain}`
{PremiumUI.EMOJIS['time']} *Scan APIs Used:* `{len(SUBDOMAIN_SOURCES)}+`
{PremiumUI.EMOJIS['wifi']} *IP Resolvers:* `{len(IP_RESOLVERS)}+`

{PremiumUI.EMOJIS['info']} *Technical Details:*
‚Ä¢ Maximum depth: 10+ levels
‚Ä¢ Concurrent threads: 30
‚Ä¢ Timeout per API: 15 seconds
‚Ä¢ IP validation: Enabled
‚Ä¢ Duplicate removal: Enabled

{PremiumUI.EMOJIS['shield']} *Features:*
‚úÖ Certificate Transparency scan
‚úÖ DNS database queries
‚úÖ Passive DNS collection
‚úÖ Web archive search
‚úÖ Threat intelligence feeds
‚úÖ TXT/JSON Export

{PremiumUI.EMOJIS['star']} *Powered by 80+ trusted APIs*
            """

            query.edit_message_text(
                text=details_msg,
                parse_mode=ParseMode.MARKDOWN
            )

        elif data == "scan_again":
            query.edit_message_text(
                text=f"{PremiumUI.EMOJIS['scan']} *New Scan*\n\n"
                     f"Send: /scan example.com\n\n"
                     f"{PremiumUI.EMOJIS['info']} Need help? Use /help",
                parse_mode=ParseMode.MARKDOWN
            )

    # FIXED: Separate command handler and callback query handler methods
    def help_command(self, update: Update, context: CallbackContext):
        """Handle /help command (from command, not callback)"""
        help_msg = self._get_help_message()
        update.message.reply_text(
            text=help_msg,
            parse_mode=ParseMode.MARKDOWN,
            disable_web_page_preview=True
        )

    def show_help_command(self, query):
        """Show help information (from callback query)"""
        help_msg = self._get_help_message()
        keyboard = [
            [
                InlineKeyboardButton(f"{PremiumUI.EMOJIS['scan']} Try Scan", callback_data="scan"),
                InlineKeyboardButton(f"{PremiumUI.EMOJIS['robot']} Channel", url=f"https://t.me/{CHANNEL_USERNAME[1:]}"),
            ]
        ]
        reply_markup = InlineKeyboardMarkup(keyboard)

        query.edit_message_text(
            text=help_msg,
            parse_mode=ParseMode.MARKDOWN,
            reply_markup=reply_markup,
            disable_web_page_preview=True
        )

    def _get_help_message(self):
        """Get help message text"""
        return f"""
{PremiumUI.EMOJIS['info']} *HELP & GUIDE* {PremiumUI.EMOJIS['info']}

*Available Commands:*
/start - Start the bot and show menu
/scan <domain> - Scan domain for subdomains & IPs
/help - Show this help message
/stats - Show bot statistics

*Usage Examples:*
‚Ä¢ /scan google.com
‚Ä¢ /scan github.com
‚Ä¢ /scan example.co.uk

*What I Do:*
{PremiumUI.EMOJIS['search']} Find all subdomains of a domain
{PremiumUI.EMOJIS['wifi']} Resolve IP addresses for each subdomain
{PremiumUI.EMOJIS['chart']} Provide detailed statistics
{PremiumUI.EMOJIS['deep']} Discover deep/nested subdomains
{PremiumUI.EMOJIS['download']} Export results as TXT/JSON files

*Features:*
{PremiumUI.EMOJIS['fire']} 80+ trusted APIs for maximum coverage
{PremiumUI.EMOJIS['speed']} Real-time progress updates
{PremiumUI.EMOJIS['shield']} No API keys required
{PremiumUI.EMOJIS['stats']} Advanced depth analysis
{PremiumUI.EMOJIS['time']} Fast scanning (15-60 seconds)
{PremiumUI.EMOJIS['file']} Export results in multiple formats

*Export Formats:*
‚Ä¢ **TXT** - Human-readable format with sections
‚Ä¢ **JSON** - Structured data for programming use

*Tips for Best Results:*
1. Use root domains (example.com not www.example.com)
2. Be patient for large domains
3. Export results for offline analysis
4. Check our channel for updates
5. Report issues to developer

*Support & Updates:*
üì¢ Channel: {CHANNEL_USERNAME}
üë®‚Äçüíª Developer: {DEVELOPER_USERNAME}

{PremiumUI.EMOJIS['warning']} *Note:* This is a free tool using public APIs.
For critical security testing, consider commercial tools.
        """

    # FIXED: Separate command handler and callback query handler methods
    def stats_command(self, update: Update, context: CallbackContext):
        """Handle /stats command (from command, not callback)"""
        stats_msg = self._get_stats_message()
        update.message.reply_text(
            text=stats_msg,
            parse_mode=ParseMode.MARKDOWN,
            disable_web_page_preview=True
        )

    def show_stats_command(self, query):
        """Show bot statistics (from callback query)"""
        stats_msg = self._get_stats_message()
        keyboard = [
            [
                InlineKeyboardButton(f"{PremiumUI.EMOJIS['scan']} Start Scan", callback_data="scan"),
                InlineKeyboardButton(f"{PremiumUI.EMOJIS['info']} Help", callback_data="help"),
            ]
        ]
        reply_markup = InlineKeyboardMarkup(keyboard)

        query.edit_message_text(
            text=stats_msg,
            parse_mode=ParseMode.MARKDOWN,
            reply_markup=reply_markup,
            disable_web_page_preview=True
        )

    def _get_stats_message(self):
        """Get stats message text"""
        total_users = len(self.user_stats)
        active_scans = len(self.active_scans)
        uptime = time.time() - self.bot_start_time

        # Calculate total scans
        total_scans = sum(user.get('scan_count', 0) for user in self.user_stats.values())

        # Format uptime
        if uptime < 60:
            uptime_str = f"{uptime:.0f}s"
        elif uptime < 3600:
            uptime_str = f"{uptime/60:.0f}m"
        elif uptime < 86400:
            uptime_str = f"{uptime/3600:.0f}h"
        else:
            uptime_str = f"{uptime/86400:.0f}d"

        return f"""
{PremiumUI.EMOJIS['stats']} *BOT STATISTICS* {PremiumUI.EMOJIS['stats']}

{PremiumUI.EMOJIS['robot']} *Bot Status:* üü¢ ONLINE
{PremiumUI.EMOJIS['users']} *Total Users:* `{total_users:,}`
{PremiumUI.EMOJIS['scan']} *Total Scans:* `{total_scans:,}`
{PremiumUI.EMOJIS['loading']} *Active Scans:* `{active_scans}`
{PremiumUI.EMOJIS['time']} *Uptime:* `{uptime_str}`

{PremiumUI.EMOJIS['satellite']} *System Info:*
‚Ä¢ APIs Available: `{len(SUBDOMAIN_SOURCES)}+`
‚Ä¢ IP Resolvers: `{len(IP_RESOLVERS)}+`
‚Ä¢ Max Threads: `30`
‚Ä¢ Version: `2026.1.0 Premium`

{PremiumUI.EMOJIS['fire']} *Premium Features:*
‚úÖ Ultra-deep subdomain discovery
‚úÖ Real-time IP resolution
‚úÖ Advanced analytics
‚úÖ Progress tracking
‚úÖ No API keys required
‚úÖ Channel integration
‚úÖ TXT/JSON Export

{PremiumUI.EMOJIS['chart']} *Performance:*
‚Ä¢ Avg scan time: 20-60 seconds
‚Ä¢ Max domains depth: 10+ levels
‚Ä¢ Concurrent capacity: 30 scans
‚Ä¢ Success rate: 95%+

üì¢ *Stay Updated:* {CHANNEL_USERNAME}
üë®‚Äçüíª *Developer:* {DEVELOPER_USERNAME}

{PremiumUI.EMOJIS['info']} *Note:* Statistics update in real-time
        """

    def export_txt_file(self, query, context: CallbackContext, domain: str):
        """Export results as TXT file"""
        try:
            # Get last scan results
            if context.user_data is None:
                query.edit_message_text(
                    text=f"{PremiumUI.EMOJIS['warning']} *No user data available!*",
                    parse_mode=ParseMode.MARKDOWN
                )
                return
                
            last_scan = context.user_data.get('last_scan', {})

            if not last_scan or last_scan.get('domain') != domain:
                query.edit_message_text(
                    text=f"{PremiumUI.EMOJIS['warning']} *No recent scan data found!*\n\n"
                         f"Please run a new scan with `/scan {domain}`",
                    parse_mode=ParseMode.MARKDOWN
                )
                return

            # Show exporting message
            query.edit_message_text(
                text=f"{PremiumUI.EMOJIS['loading']} *Preparing TXT export...*",
                parse_mode=ParseMode.MARKDOWN
            )

            # Get data
            subdomains = last_scan.get('subdomains', set())
            ip_mapping = last_scan.get('ip_mapping', {})

            # Create TXT file
            txt_file = self.export_manager.create_txt_file(domain, subdomains, ip_mapping)

            # Prepare file name
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"{domain}_subdomains_{timestamp}.txt"

            # Send file
            context.bot.send_document(
                chat_id=query.message.chat_id,
                document=txt_file,
                filename=filename,
                caption=f"{PremiumUI.EMOJIS['file']} *TXT Export Complete!*\n\n"
                       f"*Domain:* `{domain}`\n"
                       f"*Subdomains:* `{len(subdomains):,}`\n"
                       f"*File:* `{filename}`\n\n"
                       f"{PremiumUI.EMOJIS['info']} File contains:\n"
                       f"‚Ä¢ Subdomains with IPs\n"
                       f"‚Ä¢ Subdomains only list\n"
                       f"‚Ä¢ Unique IP addresses\n"
                       f"‚Ä¢ Statistics and analysis\n\n"
                       f"{PremiumUI.EMOJIS['star']} *Credits:* {DEVELOPER_USERNAME}",
                parse_mode=ParseMode.MARKDOWN
            )

            # Update message
            query.edit_message_text(
                text=f"{PremiumUI.EMOJIS['success']} *TXT File Sent!*\n\n"
                     f"Check your Telegram documents.",
                parse_mode=ParseMode.MARKDOWN
            )

        except Exception as e:
            logger.error(f"Export TXT error: {e}")
            query.edit_message_text(
                text=f"{PremiumUI.EMOJIS['error']} *Export Failed!*\n\n"
                     f"Error: {str(e)[:100]}\n\n"
                     f"Please try again.",
                parse_mode=ParseMode.MARKDOWN
            )

    def export_json_file(self, query, context: CallbackContext, domain: str):
        """Export results as JSON file"""
        try:
            # Get last scan results
            if context.user_data is None:
                query.edit_message_text(
                    text=f"{PremiumUI.EMOJIS['warning']} *No user data available!*",
                    parse_mode=ParseMode.MARKDOWN
                )
                return
                
            last_scan = context.user_data.get('last_scan', {})

            if not last_scan or last_scan.get('domain') != domain:
                query.edit_message_text(
                    text=f"{PremiumUI.EMOJIS['warning']} *No recent scan data found!*\n\n"
                         f"Please run a new scan with `/scan {domain}`",
                    parse_mode=ParseMode.MARKDOWN
                )
                return

            # Show exporting message
            query.edit_message_text(
                text=f"{PremiumUI.EMOJIS['loading']} *Preparing JSON export...*",
                parse_mode=ParseMode.MARKDOWN
            )

            # Get data
            subdomains = last_scan.get('subdomains', set())
            ip_mapping = last_scan.get('ip_mapping', {})

            # Create JSON file
            json_file = self.export_manager.create_json_file(domain, subdomains, ip_mapping)

            # Prepare file name
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"{domain}_subdomains_{timestamp}.json"

            # Send file
            context.bot.send_document(
                chat_id=query.message.chat_id,
                document=json_file,
                filename=filename,
                caption=f"{PremiumUI.EMOJIS['file']} *JSON Export Complete!*\n\n"
                       f"*Domain:* `{domain}`\n"
                       f"*Subdomains:* `{len(subdomains):,}`\n"
                       f"*File:* `{filename}`\n\n"
                       f"{PremiumUI.EMOJIS['info']} File contains structured data:\n"
                       f"‚Ä¢ Metadata and statistics\n"
                       f"‚Ä¢ Subdomain-IP mappings\n"
                       f"‚Ä¢ Depth analysis\n"
                       f"‚Ä¢ Raw data in JSON format\n\n"
                       f"{PremiumUI.EMOJIS['star']} *Credits:* {DEVELOPER_USERNAME}",
                parse_mode=ParseMode.MARKDOWN
            )

            # Update message
            query.edit_message_text(
                text=f"{PremiumUI.EMOJIS['success']} *JSON File Sent!*\n\n"
                     f"Check your Telegram documents.",
                parse_mode=ParseMode.MARKDOWN
            )

        except Exception as e:
            logger.error(f"Export JSON error: {e}")
            query.edit_message_text(
                text=f"{PremiumUI.EMOJIS['error']} *Export Failed!*\n\n"
                     f"Error: {str(e)[:100]}\n\n"
                     f"Please try again.",
                parse_mode=ParseMode.MARKDOWN
            )

# ============= MAIN FUNCTION =============
def main():
    """Start the Telegram bot"""

    # Display banner
    print(f"""
\033[1;36m
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                                                                          ‚ïë
‚ïë  üöÄ PREMIUM SUBDOMAIN SCANNER BOT (2026 EDITION)                        ‚ïë
‚ïë  üíé 80+ TRUSTED APIS | ‚ö° REAL-TIME SCANNING | üìä ADVANCED ANALYTICS     ‚ïë
‚ïë                                                                          ‚ïë
‚ïë  üë®‚Äçüíª Developer: {DEVELOPER_USERNAME}                                    ‚ïë
‚ïë  üì¢ Channel: {CHANNEL_USERNAME}                                          ‚ïë
‚ïë                                                                          ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
\033[0m
""")

    # Check bot token
    if not BOT_TOKEN or BOT_TOKEN == "YOUR_BOT_TOKEN_HERE":
        print(f"\033[1;31m[ERROR] BOT_TOKEN not set properly!\033[0m")
        print(f"\033[1;33m[INFO] Please set BOT_TOKEN in Render environment variables\033[0m")
        sys.exit(1)

    print(f"\033[1;32m[+] Starting Premium Scanner Bot (2026 Edition)...\033[0m")
    print(f"\033[1;33m[*] Trusted APIs Loaded: {len(SUBDOMAIN_SOURCES)}\033[0m")
    print(f"\033[1;33m[*] IP Resolvers: {len(IP_RESOLVERS)}\033[0m")
    print(f"\033[1;33m[!] Make sure to join: {CHANNEL_USERNAME}\033[0m")
    
    # IMPORTANT MESSAGE ABOUT BOT CONFLICT
    print(f"\033[1;31m[‚ö†Ô∏è] CRITICAL: Before deploying, make sure NO OTHER bot instance is running!\033[0m")
    print(f"\033[1;33m[üí°] TIP: If you see 'Conflict' error, stop ALL other instances first\033[0m")
    print(f"\033[1;36m[‚Üí] Bot will start in 5 seconds...\033[0m")
    
    time.sleep(5)

    try:
        # FIX 1: Start HTTP server in background thread for Render health checks
        print(f"\033[1;32m[+] Starting HTTP server for Render health checks...\033[0m")
        http_thread = threading.Thread(target=start_http_server, daemon=True)
        http_thread.start()
        time.sleep(2)

        # FIX 2: Clear any previous bot instance
        print(f"\033[1;32m[+] Clearing previous bot instance...\033[0m")
        try:
            import telegram
            temp_bot = telegram.Bot(token=BOT_TOKEN)
            # Get updates with offset to clear any pending
            updates = temp_bot.get_updates(timeout=5)
            if updates:
                print(f"‚úÖ Cleared {len(updates)} pending updates")
            # Set webhook to empty to ensure no conflict
            temp_bot.delete_webhook()
            print("‚úÖ Webhook cleared")
        except Exception as e:
            print(f"‚ÑπÔ∏è Could not clear previous instance: {e}")

        # FIX 3: Create Updater with proper settings for Render
        print(f"\033[1;32m[+] Creating bot updater...\033[0m")
        
        # Use workers=1 to avoid the warning
        updater = Updater(
            token=BOT_TOKEN, 
            use_context=True,
            workers=1,  # ‚úÖ Set to 1 instead of 0
            request_kwargs={
                'read_timeout': 30,
                'connect_timeout': 30
            }
        )
        
        dispatcher = updater.dispatcher

        # Create scanner bot instance
        scanner_bot = SubdomainScannerBot()

        # Add handlers
        dispatcher.add_handler(CommandHandler("start", scanner_bot.start))
        dispatcher.add_handler(CommandHandler("scan", scanner_bot.scan_domain))
        dispatcher.add_handler(CommandHandler("help", scanner_bot.help_command))
        dispatcher.add_handler(CommandHandler("stats", scanner_bot.stats_command))
        dispatcher.add_handler(CallbackQueryHandler(scanner_bot.button_handler))

        # FIX 4: Start polling with proper settings
        print(f"\033[1;32m[+] Starting bot polling...\033[0m")
        
        updater.start_polling(
            poll_interval=1.0,
            timeout=20,
            drop_pending_updates=True,  # ‚úÖ Clear all pending updates
            allowed_updates=['message', 'callback_query'],
            bootstrap_retries=3
        )
        
        print(f"\033[1;32m[‚úì] Bot started successfully!\033[0m")
        print(f"\033[1;33m[!] Bot is now running on Render\033[0m")
        print(f"\033[1;33m[üåê] Health check: https://your-render-url.onrender.com/health\033[0m")
        print(f"\033[1;33m[üìä] Status: https://your-render-url.onrender.com/status\033[0m")
        print(f"\033[1;32m[üöÄ] Ready to accept commands!\033[0m")

        # Keep the main thread running
        updater.idle()

    except Exception as e:
        print(f"\033[1;31m[‚úó] Error starting bot: {e}\033[0m")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()